{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71428bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "src=\"./archive/images\"\n",
    "width=150\n",
    "height=150\n",
    "\n",
    "data = dict()\n",
    "data['description'] = 'resized ({0}x{1}) images in rgb'.format(int(width), int(height))\n",
    "data['label'] = [] #Label of the classes\n",
    "data['filename'] = []\n",
    "data['data'] = [] \n",
    "\n",
    "for subdir in os.listdir(src):\n",
    "    #subdir will be the filenames\n",
    "    print(subdir)\n",
    "    #current_path=os.path.join(src, subdir)\n",
    "    current_path=src+\"/\"+subdir\n",
    "    #print(\"current_path : \", curryent_path)\n",
    "    if(subdir[-3:] in ['png', 'jpg', 'jpeg']):\n",
    "        im = imread(current_path);\n",
    "        im = resize(im, (width, height))\n",
    "        data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d5176a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "src=\"./archive/annotations\"\n",
    "width=150\n",
    "height=150\n",
    "\n",
    "data = dict()\n",
    "data['description'] = 'resized ({0}x{1})animal images in rgb'.format(int(width), int(height))\n",
    "data['label'] = [] #Label of the classes\n",
    "data['filename'] = []\n",
    "data['data'] = [] \n",
    "\n",
    "for subdir in os.listdir(src):\n",
    "    #subdir will be the filenames\n",
    "    #print(subdir)\n",
    "    current_path=src+\"/\"+subdir\n",
    "    df = pd.read_xml(current_path)\n",
    "    #num_without_mask = df[df['name'].notnull()]['name'].tolist().count(\"without_mask\");\n",
    "    series_mask = df[df['name'].notnull()]['name']\n",
    "    series_mask = series_mask[series_mask!=\"without_mask\"]\n",
    "    num_mask = series_mask.shape[0]\n",
    "    if( num_mask>1 ):\n",
    "        num_mask=1\n",
    "    data['label'].append(num_mask)\n",
    "print(len(data['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839eecbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "from skimage.io import imread\n",
    "from skimage.transform import rescale\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "mask1 = imread('./archive/images/maksssksksss99.png', as_gray=True)\n",
    " \n",
    "# scale down the image to one third\n",
    "mask1 = rescale(mask1, 1/3, mode='reflect')\n",
    "# calculate the hog and return a visual representation.\n",
    "mask1_hog, mask1_hog_img = hog(\n",
    "    mask1, pixels_per_cell=(14, 14), \n",
    "    cells_per_block=(2, 2), \n",
    "    orientations=9, \n",
    "    visualize=True, \n",
    "    block_norm='L2-Hys')\n",
    " \n",
    "print(mask1_hog.shape)\n",
    "    \n",
    "plt.imshow(mask1_hog_img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3937ee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959672ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN FUNCTION\n",
    "\n",
    "from skimage.feature import hog\n",
    "from skimage.io import imread\n",
    "from skimage.transform import rescale\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "width=150\n",
    "height=150\n",
    "\n",
    "data = dict()\n",
    "data['description'] = 'resized ({0}x{1})masked and non masked faces images in rgb'.format(int(width), int(height))\n",
    "data['label'] = [] #Label of the classes\n",
    "#data['filename'] = []\n",
    "data['data'] = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917fe088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADING THE DATASET 'ARCHIVE' from KAGGLE\n",
    "\n",
    "src=\"./archive/annotations\"\n",
    "\n",
    "for xmlFile in os.listdir(src):\n",
    "    current_path=src+\"/\"+xmlFile\n",
    "    df = pd.read_xml(current_path)\n",
    "    #num_without_mask = df[df['name'].notnull()]['name'].tolist().count(\"without_mask\");\n",
    "    series_mask = df[df['name'].notnull()]['name']\n",
    "    series_mask = series_mask[series_mask!=\"without_mask\"]\n",
    "    nb_mask = series_mask.shape[0]\n",
    "    if( nb_mask>1 ):\n",
    "        nb_mask=1\n",
    "    data['label'].append(nb_mask)\n",
    "\n",
    "src=\"./archive/images\"\n",
    "\n",
    "for picture in os.listdir(src):\n",
    "    #xmlFile will be the filenames\n",
    "    #print(picture)\n",
    "    #current_path=os.path.join(src, picture)\n",
    "    current_path=src+\"/\"+picture\n",
    "    #print(\"current_path : \", current_path)\n",
    "    if(picture[-3:] in ['png', 'jpg']):\n",
    "        img = imread(current_path, as_gray=True);\n",
    "        # scale down the image to one third\n",
    "        #img = rescale(img, 1/3, mode='reflect')\n",
    "        img = resize(img, (width, height)) #[:,:,::-1]\n",
    "        data['data'].append(img)\n",
    "        \n",
    "        # calculate the hog and its visual representation.\n",
    "        #img_hog, img_hog_image = hog(\n",
    "        #    img, pixels_per_cell=(14, 14), \n",
    "        #    cells_per_block=(2, 2), \n",
    "        #    orientations=9, \n",
    "        #    visualize=True, \n",
    "        #    block_norm='L2-Hys')\n",
    "        #data['data'].append(img_hog)\n",
    "        \n",
    "# END LOADING THE DATASET 'ARCHIVE' from KAGGLE\n",
    "\n",
    "print(len(data['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ca6f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADING THE DATASET 'RMFD'\n",
    "\n",
    "src=\"./RMFD/self-built-masked-face-recognition-dataset/AFDB_masked_face_dataset\"\n",
    "#We are in the masked-faces subdirectory\n",
    "for subdir in os.listdir(src):\n",
    "    if(os.path.isdir(src+\"/\"+subdir)):\n",
    "        # print(\"LA\")\n",
    "        for picture in os.listdir(src+\"/\"+subdir):\n",
    "            #picture will be the pitcturename\n",
    "            #print(subdir)\n",
    "            #current_path=os.path.join(src, subdir)\n",
    "            current_path=src+\"/\"+subdir+\"/\"+picture;\n",
    "            #print(\"current_path : \", current_path)\n",
    "            if(picture[-3:] in ['png', 'jpg']):\n",
    "                img = imread(current_path, as_gray=True);\n",
    "                # scale down the image to one third\n",
    "                #img = rescale(img, 1/3, mode='reflect')\n",
    "                img = resize(img, (width, height)) #[:,:,::-1]\n",
    "                data['data'].append(img)\n",
    "                data['label'].append(1)\n",
    "\n",
    "src=\"./RMFD/self-built-masked-face-recognition-dataset/AFDB_face_dataset\"\n",
    "#We are in the non-masked-faces subdirectory\n",
    "for subdir in os.listdir(src):\n",
    "    if(os.path.isdir(src+\"/\"+subdir)):\n",
    "        # print(\"LO\")\n",
    "        for picture in os.listdir(src+\"/\"+subdir):\n",
    "            #picture will be the pitcturename\n",
    "            #print(subdir)\n",
    "            #current_path=os.path.join(src, subdir)\n",
    "            current_path=src+\"/\"+subdir+\"/\"+picture\n",
    "            #print(\"current_path : \", current_path)\n",
    "            if(picture[-3:] in ['png', 'jpg']):\n",
    "                img = imread(current_path, as_gray=True);\n",
    "                # scale down the image to one third\n",
    "                #img = rescale(img, 1/3, mode='reflect')\n",
    "                img = resize(img, (width, height)) #[:,:,::-1]\n",
    "                data['data'].append(img)\n",
    "                data['label'].append(0)\n",
    "            \n",
    "# END LOADING THE DATASET 'RMFD'\n",
    "\n",
    "print(len(data['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefd08eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADING THE DATASET 'in the wild' only non masked faces\n",
    "cpt=0\n",
    "\n",
    "src=\"./in_the_wild/06000-20211215T092319Z-003/06000\"\n",
    "for picture in os.listdir(src):\n",
    "    if(cpt==40):\n",
    "        break\n",
    "    if(os.path.isfile(src+\"/\"+picture)):\n",
    "        # print(\"LA\")\n",
    "        current_path=src+\"/\"+picture;\n",
    "        #print(\"current_path : \", current_path)\n",
    "        if(picture[-3:] in ['png', 'jpg']):\n",
    "            img = imread(current_path, as_gray=True);\n",
    "            # scale down the image to one third\n",
    "            #img = rescale(img, 1/3, mode='reflect')\n",
    "            img = resize(img, (width, height)) #[:,:,::-1]\n",
    "            data['data'].append(img)\n",
    "            data['label'].append(0)\n",
    "            cpt=cpt+1\n",
    "            \n",
    "# END LOADING THE DATASET 'in the wild'\n",
    "\n",
    "print(len(data['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5531ddda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[\"data\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fdd45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array(data['data'])\n",
    "print(\"X shape :\",X.shape)\n",
    "print(\"X[0] shape :\", X[0].shape)\n",
    "y = np.array(data['label'])\n",
    "print(\"Y shape :\",y.shape)\n",
    "print(\"Y[0] shape :\", y[0].shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.2, \n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee06b574",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    " \n",
    "class RGB2GrayTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Convert an array of RGB images to grayscale\n",
    "    \"\"\"\n",
    " \n",
    "    def __init__(self):\n",
    "        pass\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"returns itself\"\"\"\n",
    "        return self\n",
    " \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"perform the transformation and return an array\"\"\"\n",
    "        return np.array([skimage.color.rgb2gray(img) for img in X])\n",
    "     \n",
    " \n",
    "class HogTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Expects an array of 2d arrays (1 channel images)\n",
    "    Calculates hog features for each img\n",
    "    \"\"\"\n",
    " \n",
    "    def __init__(self, y=None, orientations=9,\n",
    "                 pixels_per_cell=(8, 8),\n",
    "                 cells_per_block=(3, 3), block_norm='L2-Hys'):\n",
    "        self.y = y\n",
    "        self.orientations = orientations\n",
    "        self.pixels_per_cell = pixels_per_cell\n",
    "        self.cells_per_block = cells_per_block\n",
    "        self.block_norm = block_norm\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    " \n",
    "    def transform(self, X, y=None):\n",
    " \n",
    "        def local_hog(X):\n",
    "            return hog(X,\n",
    "                       orientations=self.orientations,\n",
    "                       pixels_per_cell=self.pixels_per_cell,\n",
    "                       cells_per_block=self.cells_per_block,\n",
    "                       block_norm=self.block_norm)\n",
    " \n",
    "        try: # parallel\n",
    "            return np.array([local_hog(img) for img in X])\n",
    "        except:\n",
    "            return np.array([local_hog(img) for img in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62e0800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "import skimage\n",
    " \n",
    "# create an instance of each transformer\n",
    "grayify = RGB2GrayTransformer()\n",
    "hogify = HogTransformer(\n",
    "    pixels_per_cell=(14, 14), \n",
    "    cells_per_block=(2,2), \n",
    "    orientations=9, \n",
    "    block_norm='L2-Hys'\n",
    ")\n",
    "scalify = StandardScaler()\n",
    " \n",
    "# call fit_transform on each transform converting X_train step by step\n",
    "#X_train_gray = grayify.fit_transform(X_train)\n",
    "X_train_hog = hogify.fit_transform(X_train)\n",
    "X_train_prepared = scalify.fit_transform(X_train_hog)\n",
    " \n",
    "print(X_train_prepared.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff286c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42, max_iter=1000, tol=1e-3)\n",
    "sgd_clf.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409bf102",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTS\n",
    "\n",
    "#X_test_gray = grayify.transform(X_test) Pictures in X_test already gray\n",
    "X_test_hog = hogify.transform(X_test)\n",
    "X_test_prepared = scalify.transform(X_test_hog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a18eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sgd_clf.predict(X_test_prepared)\n",
    "print(np.array(y_pred == y_test)[:60])\n",
    "print('')\n",
    "print('Percentage correct: ', 100*np.sum(y_pred == y_test)/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b981e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "arnaud_img = imread(\"Arnaud_no_mask_1.jpg\", as_gray=True);\n",
    "arnaud_img = resize(arnaud_img, (width, height)) #[:,:,::-1]\n",
    "plt.imshow(arnaud_img)\n",
    "\n",
    "liste=[]\n",
    "liste.append(arnaud_img)\n",
    "X_Ara = np.array(liste);\n",
    "\n",
    "X_Ara_hog = hogify.transform(X_Ara)\n",
    "X_Ara_prepared = scalify.transform(X_Ara_hog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b58b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sgd_clf.predict(X_Ara_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ef3164",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0df8ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pouet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b57c132",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
